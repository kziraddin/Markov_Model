{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42b9238c",
   "metadata": {},
   "source": [
    "### Importing tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba7bb328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b698a6",
   "metadata": {},
   "source": [
    "### Reading every Sherlock Holmes adventure!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d70e1dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of lines = 215021\n"
     ]
    }
   ],
   "source": [
    "story_path = \"/Users/ziko/Desktop/CSFall23/CS695_Machine_Learning/python_code/sherlock/sherlock_holmes\"\n",
    "\n",
    "def read_all_stories(story_path):\n",
    "    txt = []\n",
    "    for _, _, files in os.walk(story_path):\n",
    "        for file in files:\n",
    "            with open(os.path.join(story_path, file)) as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if line == '----------':\n",
    "                        break\n",
    "                    if line != '':\n",
    "                        txt.append(line)\n",
    "    return txt\n",
    "\n",
    "stories = read_all_stories(story_path)\n",
    "print(\"number of lines =\", len(stories))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0420de",
   "metadata": {},
   "source": [
    "### Cleaning the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d78278c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/ziko/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Download the 'punkt' resource\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1ea90ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words =  2332247\n"
     ]
    }
   ],
   "source": [
    "def clean_txt(txt):\n",
    "    cleaned_txt = []\n",
    "    for line in txt:\n",
    "        line = line.lower()\n",
    "        line = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-\\\\]\", \"\", line)\n",
    "        tokens = word_tokenize(line)\n",
    "        words = [word for word in tokens if word.isalpha()]\n",
    "        cleaned_txt+=words\n",
    "    return cleaned_txt\n",
    "\n",
    "cleaned_stories = clean_txt(stories)\n",
    "print(\"number of words = \", len(cleaned_stories))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da72799",
   "metadata": {},
   "source": [
    "### Creating the Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f77aa7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_markov_model(cleaned_stories, n_gram=2):\n",
    "    markov_model = {}\n",
    "    for i in range(len(cleaned_stories)-n_gram-1):\n",
    "        curr_state, next_state = \"\", \"\"\n",
    "        for j in range(n_gram):\n",
    "            curr_state += cleaned_stories[i+j] + \" \"\n",
    "            next_state += cleaned_stories[i+j+n_gram] + \" \"\n",
    "        curr_state = curr_state[:-1]\n",
    "        next_state = next_state[:-1]\n",
    "        if curr_state not in markov_model:\n",
    "            markov_model[curr_state] = {}\n",
    "            markov_model[curr_state][next_state] = 1\n",
    "        else:\n",
    "            if next_state in markov_model[curr_state]:\n",
    "                markov_model[curr_state][next_state] += 1\n",
    "            else:\n",
    "                markov_model[curr_state][next_state] = 1\n",
    "    \n",
    "    # calculating transition probabilities\n",
    "    for curr_state, transition in markov_model.items():\n",
    "        total = sum(transition.values())\n",
    "        for state, count in transition.items():\n",
    "            markov_model[curr_state][state] = count/total\n",
    "        \n",
    "    return markov_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3027c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_model = make_markov_model(cleaned_stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8912f9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of states =  208717\n"
     ]
    }
   ],
   "source": [
    "print(\"number of states = \", len(markov_model.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "381b5ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All possible transitions from 'the game' state: \n",
      "\n",
      "{'is up': 0.06306306306306306, 'is and': 0.036036036036036036, 'was afoot': 0.036036036036036036, 'for the': 0.036036036036036036, 'was whist': 0.036036036036036036, 'would have': 0.036036036036036036, 'in their': 0.036036036036036036, 'was up': 0.09009009009009009, 'in that': 0.036036036036036036, 'the lack': 0.036036036036036036, 'for all': 0.06306306306306306, 'is afoot': 0.036036036036036036, 'was in': 0.02702702702702703, 'is hardly': 0.02702702702702703, 'may wander': 0.02702702702702703, 'now a': 0.02702702702702703, 'my own': 0.02702702702702703, 'at any': 0.02702702702702703, 'mr holmes': 0.02702702702702703, 'ay whats': 0.02702702702702703, 'my friend': 0.02702702702702703, 'fairly by': 0.02702702702702703, 'is not': 0.02702702702702703, 'was not': 0.02702702702702703, 'worth it': 0.02702702702702703, 'you are': 0.02702702702702703, 'i am': 0.02702702702702703, 'now count': 0.02702702702702703, 'your letter': 0.02702702702702703}\n"
     ]
    }
   ],
   "source": [
    "print(\"All possible transitions from 'the game' state: \\n\")\n",
    "print(markov_model['the game'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18266768",
   "metadata": {},
   "source": [
    "### Generating Sherlock Holmes stories!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b10fd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_story(markov_model, limit=100, start='my god'):\n",
    "    n = 0\n",
    "    curr_state = start\n",
    "    next_state = None\n",
    "    story = \"\"\n",
    "    story+=curr_state+\" \"\n",
    "    while n<limit:\n",
    "        next_state = random.choices(list(markov_model[curr_state].keys()),\n",
    "                                    list(markov_model[curr_state].values()))\n",
    "        \n",
    "        curr_state = next_state[0]\n",
    "        story+=curr_state+\" \"\n",
    "        n+=1\n",
    "    return story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d23befb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.  dear holmes said i putting down the box had been her last breath in pouring out the story \n",
      "1.  dear holmes said i you hear he gives no trouble can come round to me no surprise i \n",
      "2.  dear holmes what do you make of it and when i coupled it with his or on his \n",
      "3.  dear holmes it is very pleasant in his usual mood but there was evidence of some use at \n",
      "4.  dear holmes you are surrounded by none of my fathers case to a triumphant yelp sprang upon a \n",
      "5.  dear holmes i have loved each other as our voices disturbed their slumbers toby proved to be of \n",
      "6.  dear holmes he has found it it would go if a real piece of paper with writing upon \n",
      "7.  dear holmes said i i am sure you appear to take it into their intimate conversation seemed to \n",
      "8.  dear holmes what do they care for my poor father met his end the soil was imprinted all \n",
      "9.  dear holmes and tell us all good for him one moment i was clearing up the shutters for \n",
      "10.  dear holmes i ejaculated as a peacock very much surprised if it had not said mrs toller serenely \n",
      "11.  dear holmes he has some real need for action come watson come he cried ill blow this police \n",
      "12.  dear holmes my previous letters and the box is a wise one i have also examined every stable \n",
      "13.  dear holmes i fear that you have come into being to meet him there is however a game \n",
      "14.  dear holmes i fear there is the aurora sir ah bradstreet how are you doing here his cudgel \n",
      "15.  dear holmes am i accused of having abstracted it from belfast there you have mentioned for i should \n",
      "16.  dear holmes what do you make of it i was still upon his trail from this firm that \n",
      "17.  dear holmes if i can be trusted i was finishing this little matter for these arrangements are usually \n",
      "18.  dear holmes am i justified in allowing him to tell you everything cried the poor little devil of \n",
      "19.  dear holmes what do you make of it morris drank and his military challenge of who killed john \n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(str(i)+\". \", generate_story(markov_model, start=\"dear holmes\", limit=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f42a78a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.  my dear holmes what can it be then again whom was he that i am very much indebted \n",
      "1.  my dear young lady too she was happy for i have promised to be settled the question clearly \n",
      "2.  my dear boy is nearly eighty cram full of gout too they have been infinitely more mysterious than \n",
      "3.  my dear young lady we have known i understand now mr trelawney hope i always smoke ships myself \n",
      "4.  my dear dear son the seamen had hauled the aback during the last two nights she had heard \n",
      "5.  my dear boy to put up her hand to him and it was late that night his remaining \n",
      "6.  my dear watson was enabled to produce his meretricious finales colonel emsworth the greatest living authority upon tropical \n",
      "7.  my dear watson this is the very man who had been sent off long ago to be definite \n",
      "8.  my dear holmes what do you remember a box an ivory box with a very full description of \n",
      "9.  my dear fellow for a german subject and that the man who has been a bad sign on \n",
      "10.  my dear watson yet another had the volume the mans own pouch sir his initials were of course \n",
      "11.  my dear fellow said he in turn had had it to do how could they have spotted her \n",
      "12.  my dear i hope to make it an absolutely unique one we must remember that they had met \n",
      "13.  my dear daughter alice now in one hand and a mighty queer yarn youll find it no easy \n",
      "14.  my dear sir said he you know whom they mean to have belonged to the dead mans person \n",
      "15.  my dear mr sherlock holmes is it possible gasped the spring it drew blood this box this on \n",
      "16.  my dear gregory you anticipate all my wants were few and far away down in the dark ooze \n",
      "17.  my dear watson that you are distrustful bring two friends you are sure of it mr busybody holmes \n",
      "18.  my dear fellow you will find that i must have done it would take his exercise he came \n",
      "19.  my dear watson the more deeply into the sunshine no thank you mr sandeford but i give you \n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(str(i)+\". \", generate_story(markov_model, start=\"my dear\", limit=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba664e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.  i would sooner have a savage assault upon the old church crypt at night have you examined the \n",
      "1.  i would have waited for the deep and yet i was at this instant you slipped up there \n",
      "2.  i would have nothing more to do with violence so he went down to her feet with the \n",
      "3.  i would carry my stone to beat out his brains out as i planned them i was the \n",
      "4.  i would there was no reliable test now we have one belonging to my surprise and horror the \n",
      "5.  i would have the lantern ready to uncover that we should have much difficulty in determining that said \n",
      "6.  i would have it in me its a cold night with a constancy almost unparalleled in history the \n",
      "7.  i would warn your grace however that the duchess had anything to his mother and i shall be \n",
      "8.  i would ask then leave it where it has trickled down the facts you are right mr holmes \n",
      "9.  i would suggest that we have to take a train of thought which can now be removed i \n",
      "10.  i would not have a quieter lodger or one who is at his ease in a cold hand \n",
      "11.  i would not have realized i suggested that she had read in the papers having got so far \n",
      "12.  i would have nothing more to add to your collection mr garrideb it was my appreciation of the \n",
      "13.  i would stand by each other on the cravat i could only think of none there is a \n",
      "14.  i would give it up jack for my part i walked ten miles got a train of reflection \n",
      "15.  i would have nothing more to blame than you watson said he but its cursed hard that i \n",
      "16.  i would have made my case well mr holmes from within assuring them that this little line of \n",
      "17.  i would kill her love or may have been yes by jove if it were thought possible that \n",
      "18.  i would have had some weeks in one of the man who had seated himself upon his track \n",
      "19.  i would only return etc the good steiler assured me that it had pleased him was destroyed before \n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(str(i)+\". \", generate_story(markov_model, start=\"i would\", limit=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6e902b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the case i knew also that it was thick fog and one would like to know it lord but were lurking in some retreat which had never been to his son when we broke the sad moan in which it had been devoted to the child stood beside his table it argues the degree in which he polished off his bonds which he had reached the westminster wharf and found that mycroft had preserved my rooms quite so these are the family he came over and you are gettin set on my return i found holmes in animated conversation with his father and the interests which rise up around the man who gave evidence as to the young man who was clearly a dangerous suitor with his glib irish tongue and his sister were out spending the evening tired but happy man this is the young man the look of the offices round but i shall be very much obliged to him by will he knew that such a consideration of the mysterious disappearance of your people had never to return and to carry out your assertion no i have a and to put the police let the matter rest upon me \n"
     ]
    }
   ],
   "source": [
    "print(generate_story(markov_model, start=\"the case\", limit=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0a3834",
   "metadata": {},
   "source": [
    "In summary, this script uses Markov models to generate synthetic text resembling Sherlock Holmes stories based on the patterns observed in the original text. The generated stories are produced by probabilistically selecting the next word based on the current state in the Markov model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4929db02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
